# Java ETL Pipeline (CSV â†’ PostgreSQL)

This project demonstrates an end-to-end ETL (Extract, Transform, Load) pipeline built using Java and PostgreSQL.  
The pipeline reads data from a CSV file, cleans and validates the records, and loads only valid rows into a PostgreSQL database.

---

## ðŸš€ Features

- Extracts data from CSV file
- Cleans invalid records (missing name, missing marks, invalid marks)
- Loads valid data into PostgreSQL table
- Handles real-world issues:
  - Missing columns
  - Empty values
  - Duplicate primary keys
- Uses JDBC for database connectivity
- Version controlled using Git & GitHub

---

## ðŸ›  Tech Stack

- Java  
- PostgreSQL  
- JDBC  
- Git & GitHub  

---

## ðŸ“‚ Project Structure

java-etl-pipeline/
â”‚
â”œâ”€â”€ StudentETL.java
â”œâ”€â”€ students.csv.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## ðŸ“¥ Input (CSV Sample)

id,name,marks
1,Ram,85
2,Krishn,90
3,Rahul,76
4,Ravi,93
5,Shyam,66
6,,88
7,Jenny,
8,Grace,54
9,,45
10,Rashmi,


---

## âœ… Data Cleaning Rules

A row is considered valid if:

- Name is not empty  
- Marks is not empty  
- Marks is between 0 and 100  

Invalid rows are skipped automatically.

---

## ðŸ—„ Database Setup

```sql
CREATE DATABASE etl_project;

CREATE TABLE students_clean (
    id INT PRIMARY KEY,
    name VARCHAR(50),
    marks INT
);


â–¶ How to Run
Place CSV file in project folder

Compile:

javac -cp ".;postgresql-42.7.9.jar" StudentETL.java
Run:

java -cp ".;postgresql-42.7.9.jar" StudentETL

ðŸ“¤ Output
Only valid records are inserted into PostgreSQL:

1 Ram 85
2 Krishn 90
3 Rahul 76
4 Ravi 93
5 Shyam 66
8 Grace 54


ðŸŽ¯ Learning Outcomes
Built real ETL pipeline using Java

Learned file handling and JDBC

Understood data validation and transformation

Practiced Git and GitHub workflow



ðŸ‘¤ Author
Janaki Raman Gurivindala

